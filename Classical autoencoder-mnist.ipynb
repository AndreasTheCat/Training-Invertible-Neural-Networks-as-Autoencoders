{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from architecture import MNIST_autoencoder as mnist\n",
    "from functionalities import filemanager as fm\n",
    "from functionalities import dataloader as dl\n",
    "from functionalities import loss as lo\n",
    "from functionalities import gpu \n",
    "from functionalities import plot as pl\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "milestones = [10 * x for x in range(1, 11)]\n",
    "number_dev = 0\n",
    "\n",
    "device = gpu.get_device(number_dev)\n",
    "\n",
    "\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    #x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset, testset, classes = dl.load_mnist()\n",
    "trainloader, validloader, testloader = dl.make_dataloaders(trainset, testset, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bottleneck_train_log = []\n",
    "bottleneck_test_log = []    \n",
    "    \n",
    "for bottleneck in [1, 2, 3, 4, 6, 8, 12, 16, 24, 32, 48, 64]:\n",
    "    print('bottleneck dimension: {}'.format(bottleneck))\n",
    "    model = mnist.mnist_autoencoder_deep_1024(bottleneck).to(device)\n",
    "    model.apply(init_weights)\n",
    "    #criterion = nn.MSELoss() # l2 loss\n",
    "    #criterion = lo.l1_loss() # l1 loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
    "    \n",
    "    train_loss_log = []\n",
    "    test_loss_log = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        scheduler.step()\n",
    "        for data in trainloader:\n",
    "            img, _ = data\n",
    "            img = img.view(img.size(0), -1)\n",
    "            img = Variable(img).cuda()\n",
    "            # ===================forward=====================\n",
    "            output = model(img)\n",
    "            loss = lo.l1_loss(output, img)\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "        train_loss_log.append(loss.data.item())\n",
    "        print('epoch [{}/{}], train loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data.item()))\n",
    "        if epoch % 10 == 0 or epoch == (num_epochs - 1):\n",
    "            pic = to_img(output.cpu().data)\n",
    "            save_image(pic, './mlp_img/l1_image_deep_1024_{}_{}.png'.format(bottleneck, epoch))\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            for data in testloader:\n",
    "                img, _ = data\n",
    "                img = img.view(img.size(0), -1)\n",
    "                img = Variable(img).cuda()\n",
    "                output = model(img)\n",
    "                test_loss += lo.l1_loss(output, img).data.item()\n",
    "                \n",
    "            test_loss /= len(testloader)\n",
    "            test_loss_log.append(test_loss)\n",
    "            print('test loss:{:.4f}'.format(test_loss))\n",
    "              \n",
    "    bottleneck_train_log.append(train_loss_log[-1])\n",
    "    bottleneck_test_log.append(test_loss_log[-1])\n",
    "\n",
    "    fm.save_model(model, 'l1_sim_autoencoder_deep_1024_{}'.format(bottleneck))\n",
    "    fm.save_weight(model, 'l1_sim_autoencoder_deep_1024_{}'.format(bottleneck))\n",
    "    fm.save_variable([train_loss_log, test_loss_log], \"l1_sim_autoencoder_deep_1024_{}\".format(bottleneck))\n",
    "    \n",
    "fm.save_variable([bottleneck_train_log, bottleneck_test_log], \"l1_sim_autoencoder_deep_1024_bottleneck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Reconstruction and Difference Images Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_img = 100\n",
    "grid_row_size = 10\n",
    "\n",
    "img, label = next(iter(testloader))\n",
    "img = img.view(img.size(0), -1)\n",
    "img = Variable(img).cuda()\n",
    "modelname = 'com_classic_mnist'\n",
    "\n",
    "for i in [1, 2, 3, 4, 6, 8, 12, 16, 24, 32, 48, 64]:\n",
    "    print('bottleneck dimension: {}'.format(i))\n",
    "    model = fm.load_model('l1_sim_autoencoder_{}'.format(i))\n",
    "    output = model(img)\n",
    "\n",
    "    \n",
    "    original = to_img(img.cpu().data) \n",
    "    pic = to_img(output.cpu().data)\n",
    "\n",
    "    print(\"Original Image:\")\n",
    "    pl.imshow(torchvision.utils.make_grid(original[:num_img].detach(), grid_row_size), filename=\"com_classic_mnist_{}_original\".format(i))\n",
    "    print(\"Reconstructed Image:\")\n",
    "    pl.imshow(torchvision.utils.make_grid(pic[:num_img].detach(), grid_row_size), filename=\"com_classic_mnist_{}_reconstructed\".format(i))\n",
    "    print(\"Difference:\")\n",
    "    diff_img = (original - pic + 1) / 2\n",
    "    pl.imshow(torchvision.utils.make_grid(diff_img[:num_img].detach(), grid_row_size), filename=\"com_classic_mnist_{}_difference\".format(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Recontruction Loss against Bottleneck Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = fm.load_variable(\"l1_sim_autoencoder_bottleneck\")\n",
    "y = [train, test]\n",
    "x = []\n",
    "for loss in y:\n",
    "    x.append([1, 2, 3, 4, 6, 8, 12, 16, 24, 32, 48, 64])\n",
    "\n",
    "pl.plot([x for x in [1, 2, 3, 4, 6, 8, 12, 16, 24, 32, 48, 64]], y, 'latent dimension', 'loss', ['train', 'test'], 'Train & Test Reconstruction Loss History', 'loss_l1_bottleneck') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
