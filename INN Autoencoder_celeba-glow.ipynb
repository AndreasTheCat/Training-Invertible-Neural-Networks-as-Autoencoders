{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from functionalities import dataloader as dl\n",
    "from functionalities import tracker as tk\n",
    "from architecture import INN as inn\n",
    "from functionalities import CIFAR_coder_loss as cl\n",
    "from functionalities import trainer as tr\n",
    "from functionalities import filemanager as fm\n",
    "from functionalities import plot as pl\n",
    "from functionalities import gpu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epoch = 8\n",
    "batch_size = 32\n",
    "latent_dim_lst = [2 ** x for x in range(0, 11, 2)]\n",
    "#latent_dim = 300\n",
    "number_dev = 0\n",
    "lr_init = 1e-3\n",
    "l2_reg  = 1e-6\n",
    "milestones = [6, 7, 8]\n",
    "modelname = 'celeba_INN_com_bottleneck'\n",
    "get_model = inn.celeba_inn_com\n",
    "image_size = 128\n",
    "\n",
    "device = gpu.get_device(number_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_PATH = './img_align_celeba/'\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Scale(image_size),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset = ImageFolder(IMAGE_PATH, transform)\n",
    "trainloader, testloader = dl.split_dataset(dataset, 0.2, batch_size, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model, model_params, track, MMD_loss = tr.init_model(get_model, latent_dim, 'l1', device, a_distr=0, a_disen=0)\n",
    "optimizer, scheduler = tr.init_training(model_params, lr_init, l2_reg, milestones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tr.train_bottleneck(num_epoch, get_model, 'l1', modelname, milestones, latent_dim_lst, trainloader, None, \n",
    "                            testloader, a_distr=0, a_disen=0, lr_init=lr_init, l2_reg=l2_reg, device=device, \n",
    "                            save_model=True, num_img=25, grid_row_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Reconstruction and Difference Images Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for lat_dim in latent_dim_lst:\n",
    "    print(\"Latent Dimension: \", lat_dim)\n",
    "    #print(modelname + \"_{}\".format(lat_dim), '{}_{}_{}'.format(modelname, lat_dim, num_epoch))\n",
    "    #model = fm.load_model('{}_{}_{}'.format(modelname, lat_dim, num_epoch), modelname + \"_{}\".format(lat_dim))\n",
    "    model = get_model().to(device)\n",
    "    model = fm.load_weight(model, '{}_{}_{}'.format(modelname, lat_dim, num_epoch), '{}_bottleneck'.format(modelname))\n",
    "    pl.plot_diff(model, trainloader, lat_dim, device, 25, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Recontruction Loss against Bottleneck Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, l1_rec_test, _, _, _ = fm.load_variable('bottleneck_test_loss_{}'.format(modelname), modelname)\n",
    "_, l1_rec_train, _, _, _ = fm.load_variable('bottleneck_train_loss_{}'.format(modelname), modelname)\n",
    "\n",
    "pl.plot(latent_dim_lst, [l1_rec_train, l1_rec_test], 'latent dimension', 'loss', ['train', 'test'], 'Test Reconstruction Loss History', '{}_bottleneck_History'.format(modelname)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
